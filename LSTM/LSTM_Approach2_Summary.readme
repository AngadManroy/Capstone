This approach we simply try to predict the progression of a Patient based on the learning of an LSTM model. The model would be trained on clusters of data, but the 
cornerstone of this approach is that we only consider historic data and the learning of the model would not consider patient-pecific parameters. 
This would help us understand if there is a common progression trend of the Parkinson's disease. 

Data Pre-Processing 
There were a few missing values for UPDRS 1,2,3 which were substituted inpplace with the mean values while for
UPDRS4 I substituted "0" primarily for 2 reasons-> 1. a lot of missing values ; 2.UPDRS4 sometimes is considered
irrelevant and hence not examind for early stages of Parkinson's Disease, this might also be the reason for 
missing value of UPDRS4 at most of the early stages
Now there were cases where UPDRS4  was already equal to 0. Here I ignored the fact that NA might be infered as 
early stage of PD whilst UPDRS4 with value 0 may be relatively severe condition.

Inference from model Results:
1. The graphs plotted between Average UPDRS scores and visit months indicate that there is no definitive trend
   of increase of the average UPDRS scores. The trend of increase of individual UPDRS scores have been analysed in
   in Approach 1 of LSTM. This might indicate a bad choice of model for the prediction task at hand.
2. Validation loss <1 but the r-squared value is mostly negative or nan. This indicate
   Possible Explanations:

	Overfitting: The model might be overfitting the training data, which means it is learning the noise and
	specific patterns in the training data instead of generalizing to new data. This can lead to a low 	
	validation loss but poor performance on new data (negative R-squared). Overfitting can occur when the 	
	model is too complex or when there is not enough data for training.

	Underfitting: On the other hand, if the model is underfitting, it may not capture the underlying patterns 	
	in the data, resulting in poor performance both on training and validation data (negative R-squared). In 	
	this case, the model might not be complex enough to represent the relationships in the data adequately.

	Data Quality: Issues with the data quality, such as outliers or missing values, can lead to poor model 	
	performance and negative R-squared values. It's essential to check the data for anomalies that might 	
	affect the model's ability to learn meaningful patterns.

	Inappropriate Model Choice: The chosen model architecture might not be suitable for the specific problem, 	
	leading to suboptimal performance. Different types of models might be more appropriate for different types 	
	of data and problems.
    Now, we know that data is from a trusted source, therefore the model either requires changing of parameters
    or as eearlier expexted the model is a wrong choice.
