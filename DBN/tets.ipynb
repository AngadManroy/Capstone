{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import glob\n",
    "\n",
    "# # Get a list of all CSV files in the directory\n",
    "# csv_files = glob.glob('data/*.csv')\n",
    "\n",
    "# # Create an empty DataFrame to store the combined data\n",
    "# combined_data = pd.DataFrame()\n",
    "\n",
    "# # Iterate over the CSV files and concatenate their data horizontally\n",
    "# for file in csv_files:\n",
    "#     data = pd.read_csv(file)\n",
    "#     combined_data = pd.concat([combined_data, data], axis=1)\n",
    "\n",
    "# # Save the combined data to a new CSV file\n",
    "# combined_data.to_csv('combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n8/8wwrm4fd5138rt4fqtxgcp3r0000gn/T/ipykernel_53495/565677968.py:9: DtypeWarning: Columns (0,7,8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('combined_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  visit_id  patient_id  visit_month  updrs_1  updrs_2  updrs_3  updrs_4  \\\n",
      "0     55_0        55.0          0.0     10.0      6.0     15.0      0.0   \n",
      "1     55_3        55.0          3.0     10.0      7.0     25.0      0.0   \n",
      "2     55_6        55.0          6.0      8.0     10.0     34.0      0.0   \n",
      "3     55_9        55.0          9.0      8.0      9.0     30.0      0.0   \n",
      "4    55_12        55.0         12.0     10.0     10.0     41.0      0.0   \n",
      "\n",
      "   upd23b_clinical_state_on_medication visit_id.1  visit_month.1  \\\n",
      "0                                    0       55_0            0.0   \n",
      "1                                    0       55_0            0.0   \n",
      "2                                    0       55_0            0.0   \n",
      "3                                    1       55_0            0.0   \n",
      "4                                    1       55_0            0.0   \n",
      "\n",
      "   patient_id.1 UniProt       NPX visit_id.2  visit_month.2  patient_id.2  \\\n",
      "0          55.0  O00391   11254.3       55_0              0            55   \n",
      "1          55.0  O00533  732430.0       55_0              0            55   \n",
      "2          55.0  O00584   39585.8       55_0              0            55   \n",
      "3          55.0  O14498   41526.9       55_0              0            55   \n",
      "4          55.0  O14773   31238.0       55_0              0            55   \n",
      "\n",
      "  UniProt.1                                 Peptide  PeptideAbundance  updrs  \n",
      "0    O00391                           NEQEQPLGQWHLS           11254.3    0.0  \n",
      "1    O00533                             GNPEPTFSWTK          102060.0    0.0  \n",
      "2    O00533                         IEIPSSVQQVPTIIK          174185.0    0.0  \n",
      "3    O00533  KPQSAVYSTGSNGILLC(UniMod_4)EAEGEPQPTIK           27278.9   47.0  \n",
      "4    O00533                            SMEQNGPGLEYR           30838.7   61.0  \n",
      "Mean Squared Error (MSE): 0.42170666761726766\n",
      "Accuracy: 0.9977898526738199\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load the dataset\n",
    "data = pd.read_csv('combined_data.csv')\n",
    "data.head()\n",
    "\n",
    "updrs = data['updrs_1'] + data['updrs_2'] + data['updrs_3'] + data['updrs_4'];\n",
    "data['updrs'] = updrs\n",
    "data.fillna(0, inplace=True)\n",
    "data['upd23b_clinical_state_on_medication'] = data['upd23b_clinical_state_on_medication'].replace('On', 1)\n",
    "data['upd23b_clinical_state_on_medication'] = data['upd23b_clinical_state_on_medication'].replace('Off', 0)\n",
    "print(data.head())\n",
    "# Select the relevant features\n",
    "selected_features = ['PeptideAbundance', 'NPX', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4','upd23b_clinical_state_on_medication']\n",
    "X = data[selected_features]\n",
    "y = data['updrs']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the regression model\n",
    "model = RandomForestRegressor().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate MSE on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# Evaluate the model\n",
    "\n",
    "# Add your evaluation metrics here, such as mean squared error or R-squared\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "y_pred_rounded = [round(value) for value in y_pred]\n",
    "\n",
    "# Compute accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dbn.tensorflow import SupervisedDBNRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('combined_data.csv')\n",
    "data.head()\n",
    "\n",
    "updrs = data['updrs_1'] + data['updrs_2'] + data['updrs_3'] + data['updrs_4']\n",
    "data['updrs'] = updrs\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "data['upd23b_clinical_state_on_medication'] = data['upd23b_clinical_state_on_medication'].replace('On', 1)\n",
    "data['upd23b_clinical_state_on_medication'] = data['upd23b_clinical_state_on_medication'].replace('Off', 0)\n",
    "\n",
    "# Select the relevant features\n",
    "selected_features = ['PeptideAbundance', 'NPX', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4','upd23b_clinical_state_on_medication']\n",
    "X = data[selected_features]\n",
    "y = data['updrs']\n",
    "\n",
    "# Preprocess data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# Training\n",
    "regressor = SupervisedDBNRegression(hidden_layers_structure=[100],\n",
    "                                    learning_rate_rbm=0.01,\n",
    "                                    learning_rate=0.01,\n",
    "                                    n_epochs_rbm=10,\n",
    "                                    n_iter_backprop=100,\n",
    "                                    batch_size=32,\n",
    "                                    activation_function='relu',\n",
    "                                    dropout_p=0.2)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate MSE on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Accuracy isn't typically the best metric for regression problems.\n",
    "# However, if you still want to compute it, you can convert the outputs to class labels and compute the accuracy\n",
    "y_pred_rounded = [round(value[0]) for value in y_pred]\n",
    "y_test_rounded = [round(value) for value in y_test]\n",
    "accuracy = accuracy_score(y_test_rounded, y_pred_rounded)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n8/8wwrm4fd5138rt4fqtxgcp3r0000gn/T/ipykernel_92831/1146985350.py:7: DtypeWarning: Columns (0,7,8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('combined_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/n8/8wwrm4fd5138rt4fqtxgcp3r0000gn/T/ipykernel_92831/1146985350.py:29: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From /var/folders/n8/8wwrm4fd5138rt4fqtxgcp3r0000gn/T/ipykernel_92831/1146985350.py:32: DNNRegressorV2.__init__ (from tensorflow_estimator.python.estimator.canned.dnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py:1151: RegressionHead.__init__ (from tensorflow_estimator.python.estimator.head.regression_head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py:1172: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/estimator.py:1844: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mymodel', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/lazy_loader.py:59: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /var/folders/n8/8wwrm4fd5138rt4fqtxgcp3r0000gn/T/ipykernel_92831/1146985350.py:39: numpy_input_fn (from tensorflow_estimator.python.estimator.inputs.numpy_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/estimator.py:385: StopAtStepHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     39\u001b[0m train_input_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mnumpy_input_fn(\n\u001b[1;32m     40\u001b[0m     x\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: X_train},\n\u001b[1;32m     41\u001b[0m     y\u001b[39m=\u001b[39my_train,\n\u001b[1;32m     42\u001b[0m     num_epochs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[39m# training the model\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m regressor\u001b[39m.\u001b[39;49mtrain(input_fn\u001b[39m=\u001b[39;49mtrain_input_fn, steps\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m)\n\u001b[1;32m     49\u001b[0m \u001b[39m# input function for testing\u001b[39;00m\n\u001b[1;32m     50\u001b[0m test_input_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mnumpy_input_fn(\n\u001b[1;32m     51\u001b[0m     x\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: X_test},\n\u001b[1;32m     52\u001b[0m     y\u001b[39m=\u001b[39my_test,\n\u001b[1;32m     53\u001b[0m     num_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     54\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     55\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    357\u001b[0m hooks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[1;32m    359\u001b[0m saving_listeners \u001b[39m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[0;32m--> 360\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model(input_fn, hooks, saving_listeners)\n\u001b[1;32m    361\u001b[0m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mLoss for final step: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[1;32m    362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/estimator.py:1188\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[1;32m   1187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1188\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model_default(input_fn, hooks, saving_listeners)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/estimator.py:1216\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1213\u001b[0m features, labels, input_hooks \u001b[39m=\u001b[39m (\n\u001b[1;32m   1214\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_features_and_labels_from_input_fn(input_fn, ModeKeys\u001b[39m.\u001b[39mTRAIN))\n\u001b[1;32m   1215\u001b[0m worker_hooks\u001b[39m.\u001b[39mextend(input_hooks)\n\u001b[0;32m-> 1216\u001b[0m estimator_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_model_fn(features, labels, ModeKeys\u001b[39m.\u001b[39;49mTRAIN,\n\u001b[1;32m   1217\u001b[0m                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig)\n\u001b[1;32m   1218\u001b[0m global_step_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mget_global_step(g)\n\u001b[1;32m   1219\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1220\u001b[0m                                        hooks, global_step_tensor,\n\u001b[1;32m   1221\u001b[0m                                        saving_listeners)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/estimator.py:1176\u001b[0m, in \u001b[0;36mEstimator._call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1173\u001b[0m   kwargs[\u001b[39m'\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m config\n\u001b[1;32m   1175\u001b[0m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mCalling model_fn.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1176\u001b[0m model_fn_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_fn(features\u001b[39m=\u001b[39;49mfeatures, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mDone calling model_fn.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1179\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model_fn_results, model_fn_lib\u001b[39m.\u001b[39mEstimatorSpec):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py:1159\u001b[0m, in \u001b[0;36mDNNRegressorV2.__init__.<locals>._model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_model_fn\u001b[39m(features, labels, mode, config):\n\u001b[1;32m   1158\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Call the defined shared dnn_model_fn_v2.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m   \u001b[39mreturn\u001b[39;00m dnn_model_fn_v2(\n\u001b[1;32m   1160\u001b[0m       features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   1161\u001b[0m       labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1162\u001b[0m       mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   1163\u001b[0m       head\u001b[39m=\u001b[39;49mhead,\n\u001b[1;32m   1164\u001b[0m       hidden_units\u001b[39m=\u001b[39;49mhidden_units,\n\u001b[1;32m   1165\u001b[0m       feature_columns\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(feature_columns \u001b[39mor\u001b[39;49;00m []),\n\u001b[1;32m   1166\u001b[0m       optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m   1167\u001b[0m       activation_fn\u001b[39m=\u001b[39;49mactivation_fn,\n\u001b[1;32m   1168\u001b[0m       dropout\u001b[39m=\u001b[39;49mdropout,\n\u001b[1;32m   1169\u001b[0m       config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m   1170\u001b[0m       batch_norm\u001b[39m=\u001b[39;49mbatch_norm)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py:570\u001b[0m, in \u001b[0;36mdnn_model_fn_v2\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39m# In TRAIN mode, create optimizer and assign global_step variable to\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39m# optimizer.iterations to make global_step increased correctly, as Hooks\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39m# relies on global step as step counter.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m ModeKeys\u001b[39m.\u001b[39mTRAIN:\n\u001b[0;32m--> 570\u001b[0m   optimizer \u001b[39m=\u001b[39m optimizers\u001b[39m.\u001b[39;49mget_optimizer_instance_v2(optimizer)\n\u001b[1;32m    571\u001b[0m   optimizer\u001b[39m.\u001b[39miterations \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mget_or_create_global_step()\n\u001b[1;32m    573\u001b[0m \u001b[39m# Create EstimatorSpec.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/canned/optimizers.py:127\u001b[0m, in \u001b[0;36mget_optimizer_instance_v2\u001b[0;34m(opt, learning_rate)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m opt \u001b[39min\u001b[39;00m six\u001b[39m.\u001b[39miterkeys(_OPTIMIZER_CLS_NAMES_V2):\n\u001b[1;32m    126\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m learning_rate:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mif\u001b[39;00m _optimizer_has_default_learning_rate(_OPTIMIZER_CLS_NAMES_V2[opt]):\n\u001b[1;32m    128\u001b[0m       \u001b[39mreturn\u001b[39;00m _OPTIMIZER_CLS_NAMES_V2[opt]()\n\u001b[1;32m    129\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/canned/optimizers.py:90\u001b[0m, in \u001b[0;36m_optimizer_has_default_learning_rate\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_optimizer_has_default_learning_rate\u001b[39m(opt):\n\u001b[0;32m---> 90\u001b[0m   signature \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mgetargspec(opt\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m)\n\u001b[1;32m     91\u001b[0m   default_name_to_value \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(signature\u001b[39m.\u001b[39margs[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], signature\u001b[39m.\u001b[39mdefaults))\n\u001b[1;32m     92\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m default_name_to_value\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Load the dataset\n",
    "data = pd.read_csv('combined_data.csv')\n",
    "\n",
    "updrs = data['updrs_1'] + data['updrs_2'] + data['updrs_3'] + data['updrs_4']\n",
    "data['updrs'] = updrs\n",
    "data.fillna(0, inplace=True)\n",
    "data['upd23b_clinical_state_on_medication'] = data['upd23b_clinical_state_on_medication'].replace('On', 1)\n",
    "data['upd23b_clinical_state_on_medication'] = data['upd23b_clinical_state_on_medication'].replace('Off', 0)\n",
    "\n",
    "# Select the relevant features\n",
    "selected_features = ['PeptideAbundance', 'NPX', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4', 'upd23b_clinical_state_on_medication']\n",
    "\n",
    "X = data[selected_features].values\n",
    "y = data['updrs'].values\n",
    "\n",
    "# Scaling the inputs\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create feature columns for input\n",
    "feat_cols = [tf.feature_column.numeric_column(\"x\", shape=[X_train.shape[1]])]\n",
    "\n",
    "# DNNRegressor model setup\n",
    "regressor = tf.estimator.DNNRegressor(\n",
    "    feature_columns=feat_cols, \n",
    "    hidden_units=[10,10],\n",
    "    model_dir=\"/tmp/mymodel\"\n",
    ")\n",
    "\n",
    "# input function for training\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=None,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# training the model\n",
    "regressor.train(input_fn=train_input_fn, steps=2000)\n",
    "\n",
    "# input function for testing\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# predicting the values\n",
    "y_pred_generator = regressor.predict(input_fn=test_input_fn)\n",
    "y_pred = [y['predictions'][0] for y in y_pred_generator]\n",
    "\n",
    "# Mean Squared Error calculation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n8/8wwrm4fd5138rt4fqtxgcp3r0000gn/T/ipykernel_92831/3720819062.py:10: DtypeWarning: Columns (0,7,8,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('combined_data.csv')\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  visit_id  patient_id  visit_month  updrs_1  updrs_2  updrs_3  updrs_4  \\\n",
      "0     55_0        55.0          0.0     10.0      6.0     15.0      0.0   \n",
      "1     55_3        55.0          3.0     10.0      7.0     25.0      0.0   \n",
      "2     55_6        55.0          6.0      8.0     10.0     34.0      0.0   \n",
      "3     55_9        55.0          9.0      8.0      9.0     30.0      0.0   \n",
      "4    55_12        55.0         12.0     10.0     10.0     41.0      0.0   \n",
      "\n",
      "   upd23b_clinical_state_on_medication visit_id.1  visit_month.1  \\\n",
      "0                                    0       55_0            0.0   \n",
      "1                                    0       55_0            0.0   \n",
      "2                                    0       55_0            0.0   \n",
      "3                                    1       55_0            0.0   \n",
      "4                                    1       55_0            0.0   \n",
      "\n",
      "   patient_id.1 UniProt       NPX visit_id.2  visit_month.2  patient_id.2  \\\n",
      "0          55.0  O00391   11254.3       55_0              0            55   \n",
      "1          55.0  O00533  732430.0       55_0              0            55   \n",
      "2          55.0  O00584   39585.8       55_0              0            55   \n",
      "3          55.0  O14498   41526.9       55_0              0            55   \n",
      "4          55.0  O14773   31238.0       55_0              0            55   \n",
      "\n",
      "  UniProt.1                                 Peptide  PeptideAbundance  updrs  \n",
      "0    O00391                           NEQEQPLGQWHLS           11254.3    0.0  \n",
      "1    O00533                             GNPEPTFSWTK          102060.0    0.0  \n",
      "2    O00533                         IEIPSSVQQVPTIIK          174185.0    0.0  \n",
      "3    O00533  KPQSAVYSTGSNGILLC(UniMod_4)EAEGEPQPTIK           27278.9   47.0  \n",
      "4    O00533                            SMEQNGPGLEYR           30838.7   61.0  \n",
      "Training the next RBM layer\n",
      "Epoch 1/50\n",
      "78547/78547 [==============================] - 20s 260us/step - loss: 18745877594112.0000\n",
      "Epoch 2/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745649004544.0000\n",
      "Epoch 3/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745841942528.0000\n",
      "Epoch 4/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745781125120.0000\n",
      "Epoch 5/50\n",
      "78547/78547 [==============================] - 20s 260us/step - loss: 18745846136832.0000\n",
      "Epoch 6/50\n",
      "78547/78547 [==============================] - 20s 259us/step - loss: 18745833553920.0000\n",
      "Epoch 7/50\n",
      "78547/78547 [==============================] - 21s 263us/step - loss: 18745862914048.0000\n",
      "Epoch 8/50\n",
      "78547/78547 [==============================] - 21s 265us/step - loss: 18746013908992.0000\n",
      "Epoch 9/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745888079872.0000\n",
      "Epoch 10/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745890177024.0000\n",
      "Epoch 11/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745879691264.0000\n",
      "Epoch 12/50\n",
      "78547/78547 [==============================] - 20s 258us/step - loss: 18745974063104.0000\n",
      "Epoch 13/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745898565632.0000\n",
      "Epoch 14/50\n",
      "78547/78547 [==============================] - 20s 258us/step - loss: 18745831456768.0000\n",
      "Epoch 15/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745900662784.0000\n",
      "Epoch 16/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18746022297600.0000\n",
      "Epoch 17/50\n",
      "78547/78547 [==============================] - 20s 255us/step - loss: 18745875496960.0000\n",
      "Epoch 18/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745703530496.0000\n",
      "Epoch 19/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745963577344.0000\n",
      "Epoch 20/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745825165312.0000\n",
      "Epoch 21/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745829359616.0000\n",
      "Epoch 22/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745930022912.0000\n",
      "Epoch 23/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745881788416.0000\n",
      "Epoch 24/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18746043269120.0000\n",
      "Epoch 25/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745963577344.0000\n",
      "Epoch 26/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745925828608.0000\n",
      "Epoch 27/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745852428288.0000\n",
      "Epoch 28/50\n",
      "78547/78547 [==============================] - 20s 256us/step - loss: 18745875496960.0000\n",
      "Epoch 29/50\n",
      "78547/78547 [==============================] - 20s 255us/step - loss: 18745959383040.0000\n",
      "Epoch 30/50\n",
      "78547/78547 [==============================] - 20s 255us/step - loss: 18745900662784.0000\n",
      "Epoch 31/50\n",
      "78547/78547 [==============================] - 20s 255us/step - loss: 18745875496960.0000\n",
      "Epoch 32/50\n",
      "78547/78547 [==============================] - 20s 254us/step - loss: 18745953091584.0000\n",
      "Epoch 33/50\n",
      "78547/78547 [==============================] - 20s 253us/step - loss: 18745957285888.0000\n",
      "Epoch 34/50\n",
      "78547/78547 [==============================] - 20s 255us/step - loss: 18745758056448.0000\n",
      "Epoch 35/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745770639360.0000\n",
      "Epoch 36/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745734987776.0000\n",
      "Epoch 37/50\n",
      "78547/78547 [==============================] - 20s 260us/step - loss: 18745766445056.0000\n",
      "Epoch 38/50\n",
      "78547/78547 [==============================] - 23s 289us/step - loss: 18745871302656.0000\n",
      "Epoch 39/50\n",
      "78547/78547 [==============================] - 22s 274us/step - loss: 18745955188736.0000\n",
      "Epoch 40/50\n",
      "78547/78547 [==============================] - 21s 266us/step - loss: 18745946800128.0000\n",
      "Epoch 41/50\n",
      "78547/78547 [==============================] - 22s 281us/step - loss: 18746030686208.0000\n",
      "Epoch 42/50\n",
      "78547/78547 [==============================] - 21s 273us/step - loss: 18745997131776.0000\n",
      "Epoch 43/50\n",
      "78547/78547 [==============================] - 21s 261us/step - loss: 18745850331136.0000\n",
      "Epoch 44/50\n",
      "78547/78547 [==============================] - 20s 258us/step - loss: 18745950994432.0000\n",
      "Epoch 45/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745837748224.0000\n",
      "Epoch 46/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745955188736.0000\n",
      "Epoch 47/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745942605824.0000\n",
      "Epoch 48/50\n",
      "78547/78547 [==============================] - 21s 262us/step - loss: 18745837748224.0000\n",
      "Epoch 49/50\n",
      "78547/78547 [==============================] - 20s 259us/step - loss: 18745820971008.0000\n",
      "Epoch 50/50\n",
      "78547/78547 [==============================] - 20s 257us/step - loss: 18745877594112.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the next RBM layer\n",
      "Epoch 1/50\n",
      "78547/78547 [==============================] - 47s 592us/step - loss: 0.5448\n",
      "Epoch 2/50\n",
      "78547/78547 [==============================] - 46s 588us/step - loss: 0.5409\n",
      "Epoch 3/50\n",
      "78547/78547 [==============================] - 47s 593us/step - loss: 0.5408\n",
      "Epoch 4/50\n",
      "78547/78547 [==============================] - 47s 597us/step - loss: 0.5408\n",
      "Epoch 5/50\n",
      "78547/78547 [==============================] - 46s 587us/step - loss: 0.5408\n",
      "Epoch 6/50\n",
      "78547/78547 [==============================] - 46s 590us/step - loss: 0.5408\n",
      "Epoch 7/50\n",
      "78547/78547 [==============================] - 46s 591us/step - loss: 0.5408\n",
      "Epoch 8/50\n",
      "78547/78547 [==============================] - 47s 603us/step - loss: 0.5408\n",
      "Epoch 9/50\n",
      "78547/78547 [==============================] - 49s 621us/step - loss: 0.5408\n",
      "Epoch 10/50\n",
      "78547/78547 [==============================] - 48s 610us/step - loss: 0.5408\n",
      "Epoch 11/50\n",
      "78547/78547 [==============================] - 46s 591us/step - loss: 0.5408\n",
      "Epoch 12/50\n",
      "78547/78547 [==============================] - 47s 594us/step - loss: 0.5408\n",
      "Epoch 13/50\n",
      "78547/78547 [==============================] - 47s 594us/step - loss: 0.5408\n",
      "Epoch 14/50\n",
      "78547/78547 [==============================] - 48s 605us/step - loss: 0.5408\n",
      "Epoch 15/50\n",
      "78547/78547 [==============================] - 47s 604us/step - loss: 0.5408\n",
      "Epoch 16/50\n",
      "78547/78547 [==============================] - 46s 583us/step - loss: 0.5408\n",
      "Epoch 17/50\n",
      "78547/78547 [==============================] - 43s 551us/step - loss: 0.5408\n",
      "Epoch 18/50\n",
      "78547/78547 [==============================] - 42s 541us/step - loss: 0.5408\n",
      "Epoch 19/50\n",
      "78547/78547 [==============================] - 42s 540us/step - loss: 0.5408\n",
      "Epoch 20/50\n",
      "78547/78547 [==============================] - 44s 555us/step - loss: 0.5408\n",
      "Epoch 21/50\n",
      "78547/78547 [==============================] - 45s 573us/step - loss: 0.5408\n",
      "Epoch 22/50\n",
      "78547/78547 [==============================] - 42s 541us/step - loss: 0.5408\n",
      "Epoch 23/50\n",
      "78547/78547 [==============================] - 43s 543us/step - loss: 0.5408\n",
      "Epoch 24/50\n",
      "78547/78547 [==============================] - 43s 545us/step - loss: 0.5408\n",
      "Epoch 25/50\n",
      "78547/78547 [==============================] - 43s 546us/step - loss: 0.5408\n",
      "Epoch 26/50\n",
      "78547/78547 [==============================] - 43s 543us/step - loss: 0.5408\n",
      "Epoch 27/50\n",
      "78547/78547 [==============================] - 43s 548us/step - loss: 0.5408\n",
      "Epoch 28/50\n",
      "78547/78547 [==============================] - 43s 543us/step - loss: 0.5408\n",
      "Epoch 29/50\n",
      "78547/78547 [==============================] - 43s 541us/step - loss: 0.5408\n",
      "Epoch 30/50\n",
      "78547/78547 [==============================] - 44s 559us/step - loss: 0.5408\n",
      "Epoch 31/50\n",
      "78547/78547 [==============================] - 43s 549us/step - loss: 0.5408\n",
      "Epoch 32/50\n",
      "78547/78547 [==============================] - 43s 544us/step - loss: 0.5408\n",
      "Epoch 33/50\n",
      "78547/78547 [==============================] - 45s 573us/step - loss: 0.5408\n",
      "Epoch 34/50\n",
      "78547/78547 [==============================] - 49s 620us/step - loss: 0.5408\n",
      "Epoch 35/50\n",
      "78547/78547 [==============================] - 47s 600us/step - loss: 0.5408\n",
      "Epoch 36/50\n",
      "78547/78547 [==============================] - 46s 591us/step - loss: 0.5408\n",
      "Epoch 37/50\n",
      "78547/78547 [==============================] - 48s 615us/step - loss: 0.5408\n",
      "Epoch 38/50\n",
      "78547/78547 [==============================] - 50s 631us/step - loss: 0.5408\n",
      "Epoch 39/50\n",
      "78547/78547 [==============================] - 50s 636us/step - loss: 0.5408\n",
      "Epoch 40/50\n",
      "78547/78547 [==============================] - 50s 633us/step - loss: 0.5408\n",
      "Epoch 41/50\n",
      "78547/78547 [==============================] - 49s 630us/step - loss: 0.5408\n",
      "Epoch 42/50\n",
      "78547/78547 [==============================] - 49s 626us/step - loss: 0.5408\n",
      "Epoch 43/50\n",
      "78547/78547 [==============================] - 50s 638us/step - loss: 0.5408\n",
      "Epoch 44/50\n",
      "78547/78547 [==============================] - 49s 628us/step - loss: 0.5408\n",
      "Epoch 45/50\n",
      "78547/78547 [==============================] - 48s 612us/step - loss: 0.5408\n",
      "Epoch 46/50\n",
      "78547/78547 [==============================] - 51s 643us/step - loss: 0.5408\n",
      "Epoch 47/50\n",
      "78547/78547 [==============================] - 50s 636us/step - loss: 0.5408\n",
      "Epoch 48/50\n",
      "78547/78547 [==============================] - 48s 608us/step - loss: 0.5408\n",
      "Epoch 49/50\n",
      "78547/78547 [==============================] - 50s 636us/step - loss: 0.5408\n",
      "Epoch 50/50\n",
      "78547/78547 [==============================] - 47s 600us/step - loss: 0.5408\n",
      "Epoch 1/10\n",
      "24546/24546 [==============================] - 12s 466us/step - loss: 28334919680.0000\n",
      "Epoch 2/10\n",
      "24546/24546 [==============================] - 12s 469us/step - loss: 95123.4375\n",
      "Epoch 3/10\n",
      "24546/24546 [==============================] - 12s 474us/step - loss: 4.0093\n",
      "Epoch 4/10\n",
      "24546/24546 [==============================] - 12s 486us/step - loss: 4.0092\n",
      "Epoch 5/10\n",
      "24546/24546 [==============================] - 11s 465us/step - loss: 4.0090\n",
      "Epoch 6/10\n",
      "24546/24546 [==============================] - 12s 474us/step - loss: 4.0091\n",
      "Epoch 7/10\n",
      "24546/24546 [==============================] - 12s 505us/step - loss: 4.0089\n",
      "Epoch 8/10\n",
      "24546/24546 [==============================] - 12s 482us/step - loss: 4.0091\n",
      "Epoch 9/10\n",
      "24546/24546 [==============================] - 12s 503us/step - loss: 4.0093\n",
      "Epoch 10/10\n",
      "24546/24546 [==============================] - 12s 479us/step - loss: 4.0090\n",
      "6137/6137 [==============================] - 2s 279us/step\n",
      "Mean Squared Error (MSE): 3.428342461229498\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "# Load the dataset\n",
    "data = pd.read_csv('combined_data.csv')\n",
    "data.head()\n",
    "\n",
    "updrs = data['updrs_1'] + data['updrs_2'] + data['updrs_3'] + data['updrs_4']\n",
    "data['updrs'] = updrs\n",
    "data.fillna(0, inplace=True)\n",
    "data['upd23b_clinical_state_on_medication'] = data['upd23b_clinical_state_on_medication'].replace('On', 1)\n",
    "data['upd23b_clinical_state_on_medication'] = data['upd23b_clinical_state_on_medication'].replace('Off', 0)\n",
    "print(data.head())\n",
    "\n",
    "# Select the relevant features\n",
    "selected_features = ['PeptideAbundance', 'NPX', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4','upd23b_clinical_state_on_medication']\n",
    "X = data[selected_features]\n",
    "y = data['updrs']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the RBM and DBN classes as shown in the previous code snippet\n",
    "class RBM:\n",
    "    def __init__(self, input_shape, output_shape, learning_rate=0.1, batch_size=10, epochs=50):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.rbm_model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.output_shape, activation='sigmoid', input_shape=(self.input_shape,)))\n",
    "        model.add(Dense(self.input_shape, activation='sigmoid'))\n",
    "        return model\n",
    "\n",
    "    def train(self, train_data):\n",
    "        self.rbm_model.compile(optimizer=SGD(self.learning_rate), loss='mean_squared_error')\n",
    "        x_train = np.array(train_data)\n",
    "        self.rbm_model.fit(x_train, x_train, batch_size=self.batch_size, epochs=self.epochs, verbose=True)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.rbm_model.layers[0].get_weights()\n",
    "\n",
    "class DBN:\n",
    "    def __init__(self, rbm_list):\n",
    "        self.rbm_list = rbm_list\n",
    "\n",
    "    def pretrain(self, train_data):\n",
    "        temp_train = train_data\n",
    "        for rbm in self.rbm_list:\n",
    "            print(\"Training the next RBM layer\")\n",
    "            rbm.train(temp_train)\n",
    "            weights, biases = rbm.get_weights()\n",
    "            temp_train = np.tanh(np.dot(temp_train, weights) + biases) \n",
    "# Initialize the RBMs and the DBN\n",
    "rbm1 = RBM(input_shape=X_train.shape[1], output_shape=512)\n",
    "rbm2 = RBM(input_shape=512, output_shape=128)\n",
    "\n",
    "dbn = DBN([rbm1, rbm2])\n",
    "\n",
    "# Pretrain the DBN\n",
    "dbn.pretrain(X_train)\n",
    "\n",
    "# Build the regression model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate MSE on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the MSE\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
